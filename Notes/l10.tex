\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[czech, english]{babel}
\usepackage[left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{tikz}
\usetikzlibrary{shapes.geometric}
\usepackage{hyperref}


% Itemize environment with small skips
\newenvironment{packeditemize}{
\begin{itemize}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{itemize}}


% Fancy footnote....
\usepackage{fancyhdr}
\pagestyle{fancy}
\usepackage{lastpage}
\rfoot{MATH 566 - 10, page \thepage/\pageref{LastPage}}
\cfoot{}
\rhead{}
\lhead{}
\renewcommand{\headrulewidth}{0pt}
\renewcommand{\footrulewidth}{0pt}


\newtheorem{theorem*}{Theorem} 

% Itemize environment with small skips
\newenvironment{packedenumerate}{
\begin{enumerate}
  \setlength{\itemsep}{1pt}
  \setlength{\parskip}{0pt}
  \setlength{\parsep}{0pt}
}{\end{enumerate}}


\newcounter{excounter}
\setcounter{excounter}{1}
\newcommand\question[2]{\vskip 1em  \noindent\textbf{\arabic{excounter}\addtocounter{excounter}{1}:} \emph{#1} \noindent#2}
\newcommand\solution[1]{\vskip 0.5em \noindent\textbf{Solution:} #1}
\newcommand\like{\par \noindent\emph{(This question is: good - bad - ugly? Difficulty: 0-10:\hskip 3em )}} 

\newcommand\lecturer[1]{\textbf{#1}}
\newcommand\hideforstudent[1]{#1}


%\renewcommand\lecturer[1]{{\color{white} \textbf{#1} }}
%\renewcommand\hideforstudent[1]{{\color{white} #1 }}
%\renewcommand\solution[1]{{\color{white} \vskip 0.5em \noindent\textbf{Solution:} #1 }}



\setlength{\parindent}{0cm}
\setlength{\parskip}{0.1cm}

\begin{document}

Fall  2016, MATH-566

\centerline{{\Large \textbf{Linear Programming Algorithms - Interior point methods}}}


Source: Chapter 11 of \href{http://stanford.edu/~boyd/cvxbook/}{Convex Optimization, Stephen Boyd and Lieven Vandenberghe}

Let
\[
(P)
\begin{cases}
\text{minimize} & f(\mathbf{x}) \\
\text{subject to} & g_i(\mathbf{x}) \leq 0 \text{ for } i = 1,\ldots,m
\end{cases}
\]
where $f,g$ are convex, twice continuously differentiable and optimal solution $\mathbf{x}^\star$ exists.\\
Moreover, let $(P)$ be \emph{superconsistent}, that is $\exists \mathbf{x}, \forall i, g_i(\mathbf{x}) < 0$. In other words, the set of feasible solutions have full dimension.

(the setup covers linear, quadratic, geometric, semidefinite, \ldots programming).

\textbf{Idea:} Change the $(P)$ to a problem without constraints but difficult objective function.

Let 
\[
(P') = \text{minimize } f(\mathbf{x}) + \sum_{i=1}^mI(g_i(\mathbf{x})),
\]
where $I$ is an indicator function
\[
I(u) = \begin{cases} 	0 & \text{ if } u \leq 0 \\
+\infty & \text{ if } u > 0.
\end{cases}
\]

\question{}{What is the optimal solution to $(P')$?}

\solution{$\mathbf{x}^\star$ The function $I$ works like infinite penalty for violating constraints.}


\question{}{Can you solve $(P')$ by methods from calculus?}
\solution{
No, because $I$ has no derivative.
}

Use approximation of $I(u) \approx  - c \log(-u)$, where $c > 0$.
\question{}{
Sketch $I(u)$ and its approximations. Is the approximation better when $c$ is large or small?
}
\solution{
\begin{center}
\begin{tikzpicture}
\draw[help lines](-5,-1) grid (1,5);
\end{tikzpicture}
\end{center}
Approximation improves as $c \rightarrow 0$.
}

For $t > 0$, we consider a smooth unconstrained approximation of $(P')$
\[
\text{ minimize } f(\mathbf{x}) - \frac{1}{t} \sum_{i=1}^m \log(- g_i(\mathbf{x})).
\]

\newpage

Define \emph{logarithmic barrier function}
\[
\Phi(\mathbf{x}) = - \sum_{i=1}^m \log(-g_i(\mathbf{x})),
\]
for all $\mathbf{x}$ where $g_i(\mathbf{x}) < 0$   (interior of feasible solutions)

\textbf{Analytic center} of the set  $S = \{ \mathbf{x}: g_i(\mathbf{x}) \leq 0\} \subseteq \mathbb{R}^n$
 is $\mathbf{x}^\star$ minimizing $\Phi(\mathbf{x})$ over all $\mathbf{x} \in S$.

\question{}{
Find the analytic center of a square in $\mathbf{R}^2$ defined by equations
\[
x_1 \geq 0, x_2 \geq 0, x_1 \leq 1, x_2 \leq 1
\]
}
\solution{
First rewrite in the form $g_i(\mathbf{x}) \leq 0$.
\[
-x_1 \leq 0, -x_2 \leq 0, x_1-1\leq0, x_2-1 \leq0.
\]
Now we write $\Phi(\mathbf{x})$.
\[
\Phi(x_1,x_2) = - \left( \log (x_1) + \log(x_2) + \log(1-x_1) + \log(1-x_2)\right)
\]
We investigate partial derivatives and let them $=0$.
\begin{align*}
0 &= \frac{\partial \Phi(x_1,x_2)}{\partial x_i} = -\frac{1}{x_i} + \frac{1}{1-x_i}\\
1-x_i   &= x_i \\
x_i      &= \frac{1}{2}. 
\end{align*}
The second derivatives at $(\frac{1}{2},\frac{1}{2})$ are
\begin{align*}
\frac{\partial^2 \Phi(x_1,x_2)}{\partial x_i\partial x_j} = 0 \\
\frac{\partial^2 \Phi(x_1,x_2)}{\partial^2 x_i} = \frac{1}{x_i^2} +  \frac{1}{(1-x_i)^2} = 8\\
\end{align*}
This shows that the Hessian at the critical point
\[
\begin{bmatrix}
 8 & 0 \\
 0 & 8
\end{bmatrix}
\]
which is positive definite. Hence $(\frac{1}{2}, \frac12)$ is minimum. Notice that $\Phi(\mathbf{x})$ is convex, so we could argue that any critical point is minimum.
The analytic center is $(\frac{1}{2},\frac{1}{2})$.
}

\question{}{
Find the analytic center of a square in $\mathbf{R}^2$ defined by equations
\[
x_1 \geq 0, x_2 \geq 0, (1-x_1)^3 \geq 0, (1-x_2)^3 \geq 0.
\]
Notice it is possible to define center even if functions are not convex 
everywhere and the center depends on the functions.
}
\solution{
\[
\Phi(x_1,x_2) = - \left( \log (x_1) + \log(x_2) + \log((1-x_1)^3) + \log((1-x_2)^3)\right)
\]
\begin{align*}
0 &= \frac{\partial \Phi(x_1,x_2)}{\partial x_i} = -\frac{1}{x_i} + \frac{3}{1-x_i}\\
x_i &= \frac{1}{4} 
\end{align*}
The analytic center is $(\frac{1}{4}, \frac{1}{4})$.
}


%\newpage



For $t > 0$ define $\mathbf{x}^\star(t)$ as the optimal solution of 
\[
(P_t) = \text{ minimize } tf(\mathbf{x}) + \Phi(\mathbf{x}).
\]
(assume that the optimal solution is unique)

\textbf{Central path} is $\{\textbf{x}^\star(t):  t \geq 0   \}$.


Interior point method idea: Start in the analytical center and follow the central path.

In iterations increase $t$ and recompute the new optimum using Newton's method.
Recall that Newton's method works well if the initial point of Newton's method is close
to the optimal solution. With small increases of $t$, the starting point is close to the
optimum.

\begin{center}
\begin{tikzpicture}
\draw (0,0) -- (3,1) -- (3,3) -- (0,3) -- cycle ;
\draw[line width=1pt,-latex,dashed] (1.5,1.5) to[bend left=20] (3,3);
\end{tikzpicture}
\end{center}

There exists a notion of dual program $(D)$ for $(P)$,  (based on Karush-Kuhn-Tucker theorem).
It gives solutions to the dual $\mathbf{y}^\star(t)$ such that
\[
f(\mathbf{x}^\star(t)) - h(\mathbf{y}^\star(t)) \leq \frac{m}{t},
\]
where $h$ is the objective function of the dual program.
Hence the central path converges to $\mathbf{x}^\star$ for $(P)$.





\end{document}


\newpage 

\question{}{
Let $(LP) = \text{mininize }\mathbf{c}^T\mathbf{x} \text{ s.t. } A\mathbf{x} \leq \mathbf{b}$, where $A \in \mathbb{R}^{m \times n}$.  Write $\Phi(\mathbf{x}$). Use tools from calculus to compute the corresponding central path. What can you say about the Hessain?
}
\solution{
\[
\Phi(\mathbf{x}) = - \sum_{i=1}^m\log(b_i-\mathbf{a}_i\mathbf{x}),
\]
where $a_i$ is $i$th row of $A$.

The central path is minimizing
\[
z_t(\mathbf{x}) = tf(\mathbf{x}) + \Phi(\mathbf{x}) = t\mathbf{c}^T\mathbf{x} - \sum_{i=1}^m\log(b_i-\mathbf{a}_i^T\mathbf{x})
\]

In the minimum, we have $\nabla z_t(\mathbf{x}) = 0$. This gives
\[
0 = \nabla z_t(\mathbf{x}) = t\mathbf{c} + \sum_{i=1}^m\frac{1}{b_i - \mathbf{a}_i^T\mathbf{x}}\mathbf{a_i}
\]
Now the Hessian is
\[
\nabla^2 z_t(\mathbf{x}) = \sum_{i=1}^m\frac{1}{(b_i - \mathbf{a}_i^T\mathbf{x})^2}\mathbf{a_i}\mathbf{a_i}^T 
\]
Notice that the Hessian is a positive semidefinite matrix. Hence everytime the determinant is zero, get a minimum.
}
In the end we obtained 
\[
t\mathbf{c} = -\nabla \Phi(\mathbf{x}^\star(t)).
\]
Since $\nabla \Phi(\mathbf{x})$ is perpendicular to the level curve $\{\mathbf{x}: \Phi(\mathbf{x}) = \Phi(\mathbf{x}^\star(t) \}$, plane $\mathbf{c}^T\mathbf{x} = \mathbf{c}^T\mathbf{x}^\star(t)$ is
a tangent of the level curve for $\Phi$.

\begin{center}
\begin{tikzpicture}
\draw (0,0) -- (3,1) -- (3,3) -- (0,3) -- cycle ;
\draw[line width=1pt,-latex,dashed] (1.5,1.5) to[bend left=20] (3,3);
\end{tikzpicture}
\end{center}










\question{}{
Compute gradient and Hessian of $\Phi(\mathbf{x})$.
}
\solution
{
\[
\nabla \Phi(\mathbf{x}) = \sum_{i=1}^m \frac{1}{-g_i(\mathbf{x})} \nabla g_i(\mathbf{x})
\]
\[
\nabla^2 \Phi(\mathbf{x}) = H\Phi(\mathbf{x}) = \sum_{i=1}^m \frac{1}{g_i(\mathbf{x})^2} \nabla g_i(\mathbf{x})  \nabla g_i(\mathbf{x})^T  + \sum_{i=1}^m\frac{1}{-g_i(x)} Hg_i(x)
\]
}




Let $S = \{ \mathbf{x}: g_i(\mathbf{x}) \geq 0\} \subseteq \mathbb{R}^n$, where $g_i: \mathbb{R}^n \rightarrow \mathbb{R}$. Suppose the interior $S^0$ of $S$ is non-empty.
So $S^0 = \{ \mathbf{x}: g_i(\mathbf{x}) > 0\}$

The \textbf{analytic center} of $S$ is vector $\mathbf{x}$ that is solving
\[
     \text{minimize}  -\sum_i \log( g_i(\mathbf{x})) \text{ over all } \mathbf{x} \in S^0
\]





\question{}{
Notice that the same set can be described also by
by $x_i \geq 0$ and $(1-x_i)^4 \geq 0$. Suppose $i \in \{1,2,3\}$. 
Compute the analytic center for this new set of constraints.
}







